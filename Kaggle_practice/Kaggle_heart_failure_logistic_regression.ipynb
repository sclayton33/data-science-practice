{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load in the processed dataset from the previous notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dislpay full column widths and all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df = pd.read_csv('/media/veracrypt3/Cloud/Datasets/Kaggle/heart_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>ASY</th>\n",
       "      <th>ATA</th>\n",
       "      <th>NAP</th>\n",
       "      <th>TA</th>\n",
       "      <th>LVH</th>\n",
       "      <th>Normal</th>\n",
       "      <th>ST</th>\n",
       "      <th>N</th>\n",
       "      <th>Y</th>\n",
       "      <th>Down</th>\n",
       "      <th>Flat</th>\n",
       "      <th>Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>150</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  HeartDisease  F  M  \\\n",
       "0   40        140        289.0          0    172      0.0             0  0  1   \n",
       "1   49        160        180.0          0    156      1.0             1  1  0   \n",
       "2   37        130        283.0          0     98      0.0             0  0  1   \n",
       "3   48        138        214.0          0    108      1.5             1  1  0   \n",
       "4   54        150        195.0          0    122      0.0             0  0  1   \n",
       "\n",
       "   ASY  ATA  NAP  TA  LVH  Normal  ST  N  Y  Down  Flat  Up  \n",
       "0    0    1    0   0    0       1   0  1  0     0     0   1  \n",
       "1    0    0    1   0    0       1   0  1  0     0     1   0  \n",
       "2    0    1    0   0    0       0   1  1  0     0     0   1  \n",
       "3    1    0    0   0    0       1   0  0  1     0     1   0  \n",
       "4    0    0    1   0    0       1   0  1  0     0     0   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create X and Y datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 40. , 140. , 289. ,   0. , 172. ,   0. ,   0. ,   1. ,   0. ,\n",
       "          1. ,   0. ,   0. ,   0. ,   1. ,   0. ,   1. ,   0. ,   0. ,\n",
       "          0. ,   1. ],\n",
       "       [ 49. , 160. , 180. ,   0. , 156. ,   1. ,   1. ,   0. ,   0. ,\n",
       "          0. ,   1. ,   0. ,   0. ,   1. ,   0. ,   1. ,   0. ,   0. ,\n",
       "          1. ,   0. ],\n",
       "       [ 37. , 130. , 283. ,   0. ,  98. ,   0. ,   0. ,   1. ,   0. ,\n",
       "          1. ,   0. ,   0. ,   0. ,   0. ,   1. ,   1. ,   0. ,   0. ,\n",
       "          0. ,   1. ],\n",
       "       [ 48. , 138. , 214. ,   0. , 108. ,   1.5,   1. ,   0. ,   1. ,\n",
       "          0. ,   0. ,   0. ,   0. ,   1. ,   0. ,   0. ,   1. ,   0. ,\n",
       "          1. ,   0. ],\n",
       "       [ 54. , 150. , 195. ,   0. , 122. ,   0. ,   0. ,   1. ,   0. ,\n",
       "          0. ,   1. ,   0. ,   0. ,   1. ,   0. ,   1. ,   0. ,   0. ,\n",
       "          0. ,   1. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(proc_df.loc[:, proc_df.columns != 'HeartDisease'])  # select all columns except 'HeartDisease'\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.asarray(proc_df['HeartDisease'])\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.43220634,  0.41462669,  0.94076249, -0.55173333,  1.38333943,\n",
       "        -0.83150225, -0.51630861,  0.51630861, -1.08542493,  2.07378351,\n",
       "        -0.53152374, -0.22981048, -0.50782627,  0.81501339, -0.49078105,\n",
       "         0.82431012, -0.82431012, -0.27160724, -1.00109111,  1.14957339],\n",
       "       [-0.47805725,  1.52635965, -0.99871403, -0.55173333,  0.75473573,\n",
       "         0.10625149,  1.9368261 , -1.9368261 , -1.08542493, -0.48221041,\n",
       "         1.88138352, -0.22981048, -0.50782627,  0.81501339, -0.49078105,\n",
       "         0.82431012, -0.82431012, -0.27160724,  0.99891008, -0.86988791],\n",
       "       [-1.75025603, -0.14123979,  0.83400232, -0.55173333, -1.52395266,\n",
       "        -0.83150225, -0.51630861,  0.51630861, -1.08542493,  2.07378351,\n",
       "        -0.53152374, -0.22981048, -0.50782627, -1.22697371,  2.0375685 ,\n",
       "         0.82431012, -0.82431012, -0.27160724, -1.00109111,  1.14957339],\n",
       "       [-0.58407381,  0.30345339, -0.3937397 , -0.55173333, -1.13107535,\n",
       "         0.57512835,  1.9368261 , -1.9368261 ,  0.92129817, -0.48221041,\n",
       "        -0.53152374, -0.22981048, -0.50782627,  0.81501339, -0.49078105,\n",
       "        -1.21313565,  1.21313565, -0.27160724,  0.99891008, -0.86988791],\n",
       "       [ 0.05202558,  0.97049317, -0.73181359, -0.55173333, -0.58104712,\n",
       "        -0.83150225, -0.51630861,  0.51630861, -1.08542493, -0.48221041,\n",
       "         1.88138352, -0.22981048, -0.50782627,  0.81501339, -0.49078105,\n",
       "         0.82431012, -0.82431012, -0.27160724, -1.00109111,  1.14957339]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/test split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (733, 20) (733,)\n",
      "Test set: (184, 20) (184,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "print('Train set:', X_train.shape, Y_train.shape)\n",
    "print('Test set:', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=0.1, solver='liblinear').fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40374797, 0.59625203],\n",
       "       [0.05930455, 0.94069545],\n",
       "       [0.78707569, 0.21292431],\n",
       "       [0.29459984, 0.70540016],\n",
       "       [0.97380357, 0.02619643],\n",
       "       [0.05084847, 0.94915153],\n",
       "       [0.05662423, 0.94337577],\n",
       "       [0.14324629, 0.85675371],\n",
       "       [0.41103367, 0.58896633],\n",
       "       [0.90902911, 0.09097089],\n",
       "       [0.97472772, 0.02527228],\n",
       "       [0.0257794 , 0.9742206 ],\n",
       "       [0.58702534, 0.41297466],\n",
       "       [0.94406069, 0.05593931],\n",
       "       [0.00932095, 0.99067905],\n",
       "       [0.77469372, 0.22530628],\n",
       "       [0.98338647, 0.01661353],\n",
       "       [0.76155855, 0.23844145],\n",
       "       [0.95763811, 0.04236189],\n",
       "       [0.06007153, 0.93992847],\n",
       "       [0.94428863, 0.05571137],\n",
       "       [0.05602015, 0.94397985],\n",
       "       [0.10630286, 0.89369714],\n",
       "       [0.98924075, 0.01075925],\n",
       "       [0.96017899, 0.03982101],\n",
       "       [0.07996723, 0.92003277],\n",
       "       [0.98761422, 0.01238578],\n",
       "       [0.3473298 , 0.6526702 ],\n",
       "       [0.05247398, 0.94752602],\n",
       "       [0.01581716, 0.98418284],\n",
       "       [0.04002144, 0.95997856],\n",
       "       [0.47292678, 0.52707322],\n",
       "       [0.10343997, 0.89656003],\n",
       "       [0.05525131, 0.94474869],\n",
       "       [0.18711826, 0.81288174],\n",
       "       [0.02550012, 0.97449988],\n",
       "       [0.18285364, 0.81714636],\n",
       "       [0.04903374, 0.95096626],\n",
       "       [0.90046741, 0.09953259],\n",
       "       [0.98738581, 0.01261419],\n",
       "       [0.01608617, 0.98391383],\n",
       "       [0.98051894, 0.01948106],\n",
       "       [0.33958067, 0.66041933],\n",
       "       [0.08694484, 0.91305516],\n",
       "       [0.41842996, 0.58157004],\n",
       "       [0.04359015, 0.95640985],\n",
       "       [0.1686554 , 0.8313446 ],\n",
       "       [0.04737763, 0.95262237],\n",
       "       [0.2212421 , 0.7787579 ],\n",
       "       [0.28881241, 0.71118759],\n",
       "       [0.14231389, 0.85768611],\n",
       "       [0.36550001, 0.63449999],\n",
       "       [0.96354097, 0.03645903],\n",
       "       [0.13479118, 0.86520882],\n",
       "       [0.96800767, 0.03199233],\n",
       "       [0.05993798, 0.94006202],\n",
       "       [0.1426239 , 0.8573761 ],\n",
       "       [0.07230988, 0.92769012],\n",
       "       [0.98255769, 0.01744231],\n",
       "       [0.94859278, 0.05140722],\n",
       "       [0.4957891 , 0.5042109 ],\n",
       "       [0.98708764, 0.01291236],\n",
       "       [0.95931659, 0.04068341],\n",
       "       [0.19906267, 0.80093733],\n",
       "       [0.09321811, 0.90678189],\n",
       "       [0.42190634, 0.57809366],\n",
       "       [0.12595121, 0.87404879],\n",
       "       [0.08025887, 0.91974113],\n",
       "       [0.96830754, 0.03169246],\n",
       "       [0.98288346, 0.01711654],\n",
       "       [0.05228056, 0.94771944],\n",
       "       [0.59390076, 0.40609924],\n",
       "       [0.89654017, 0.10345983],\n",
       "       [0.45713975, 0.54286025],\n",
       "       [0.34742529, 0.65257471],\n",
       "       [0.66583078, 0.33416922],\n",
       "       [0.65163345, 0.34836655],\n",
       "       [0.77237318, 0.22762682],\n",
       "       [0.90404798, 0.09595202],\n",
       "       [0.63273311, 0.36726689],\n",
       "       [0.60679786, 0.39320214],\n",
       "       [0.85336331, 0.14663669],\n",
       "       [0.06801597, 0.93198403],\n",
       "       [0.84098741, 0.15901259],\n",
       "       [0.01866671, 0.98133329],\n",
       "       [0.55292855, 0.44707145],\n",
       "       [0.91850063, 0.08149937],\n",
       "       [0.98425084, 0.01574916],\n",
       "       [0.04534191, 0.95465809],\n",
       "       [0.51340498, 0.48659502],\n",
       "       [0.13673922, 0.86326078],\n",
       "       [0.20547149, 0.79452851],\n",
       "       [0.79060455, 0.20939545],\n",
       "       [0.64109648, 0.35890352],\n",
       "       [0.18061475, 0.81938525],\n",
       "       [0.14060657, 0.85939343],\n",
       "       [0.64217827, 0.35782173],\n",
       "       [0.06230694, 0.93769306],\n",
       "       [0.0537504 , 0.9462496 ],\n",
       "       [0.39792089, 0.60207911],\n",
       "       [0.97848631, 0.02151369],\n",
       "       [0.34462782, 0.65537218],\n",
       "       [0.06735011, 0.93264989],\n",
       "       [0.20432121, 0.79567879],\n",
       "       [0.04503699, 0.95496301],\n",
       "       [0.07690355, 0.92309645],\n",
       "       [0.97739934, 0.02260066],\n",
       "       [0.89856651, 0.10143349],\n",
       "       [0.51037816, 0.48962184],\n",
       "       [0.06306627, 0.93693373],\n",
       "       [0.4079507 , 0.5920493 ],\n",
       "       [0.69540804, 0.30459196],\n",
       "       [0.55988285, 0.44011715],\n",
       "       [0.91230734, 0.08769266],\n",
       "       [0.95508272, 0.04491728],\n",
       "       [0.0911742 , 0.9088258 ],\n",
       "       [0.03418929, 0.96581071],\n",
       "       [0.07363657, 0.92636343],\n",
       "       [0.04051259, 0.95948741],\n",
       "       [0.05705174, 0.94294826],\n",
       "       [0.96229455, 0.03770545],\n",
       "       [0.05753815, 0.94246185],\n",
       "       [0.14946102, 0.85053898],\n",
       "       [0.94975976, 0.05024024],\n",
       "       [0.86607687, 0.13392313],\n",
       "       [0.95106881, 0.04893119],\n",
       "       [0.75974892, 0.24025108],\n",
       "       [0.9223829 , 0.0776171 ],\n",
       "       [0.89331407, 0.10668593],\n",
       "       [0.39868963, 0.60131037],\n",
       "       [0.15045415, 0.84954585],\n",
       "       [0.86010512, 0.13989488],\n",
       "       [0.16129774, 0.83870226],\n",
       "       [0.20101974, 0.79898026],\n",
       "       [0.62778335, 0.37221665],\n",
       "       [0.19201565, 0.80798435],\n",
       "       [0.22353267, 0.77646733],\n",
       "       [0.07339594, 0.92660406],\n",
       "       [0.87972535, 0.12027465],\n",
       "       [0.42833984, 0.57166016],\n",
       "       [0.97715261, 0.02284739],\n",
       "       [0.12644469, 0.87355531],\n",
       "       [0.92559896, 0.07440104],\n",
       "       [0.94630859, 0.05369141],\n",
       "       [0.01149905, 0.98850095],\n",
       "       [0.407448  , 0.592552  ],\n",
       "       [0.74484017, 0.25515983],\n",
       "       [0.92461252, 0.07538748],\n",
       "       [0.03016774, 0.96983226],\n",
       "       [0.20520622, 0.79479378],\n",
       "       [0.66089676, 0.33910324],\n",
       "       [0.07499222, 0.92500778],\n",
       "       [0.95392372, 0.04607628],\n",
       "       [0.31361998, 0.68638002],\n",
       "       [0.13130452, 0.86869548],\n",
       "       [0.69333749, 0.30666251],\n",
       "       [0.37778947, 0.62221053],\n",
       "       [0.28800631, 0.71199369],\n",
       "       [0.83918439, 0.16081561],\n",
       "       [0.10050872, 0.89949128],\n",
       "       [0.97328286, 0.02671714],\n",
       "       [0.02121894, 0.97878106],\n",
       "       [0.07926616, 0.92073384],\n",
       "       [0.93425679, 0.06574321],\n",
       "       [0.07642857, 0.92357143],\n",
       "       [0.31580867, 0.68419133],\n",
       "       [0.85915007, 0.14084993],\n",
       "       [0.04776255, 0.95223745],\n",
       "       [0.01524843, 0.98475157],\n",
       "       [0.75965475, 0.24034525],\n",
       "       [0.14388223, 0.85611777],\n",
       "       [0.98359993, 0.01640007],\n",
       "       [0.54002526, 0.45997474],\n",
       "       [0.59643782, 0.40356218],\n",
       "       [0.02374041, 0.97625959],\n",
       "       [0.26084933, 0.73915067],\n",
       "       [0.98606755, 0.01393245],\n",
       "       [0.0181489 , 0.9818511 ],\n",
       "       [0.05013217, 0.94986783],\n",
       "       [0.13588029, 0.86411971],\n",
       "       [0.89162336, 0.10837664],\n",
       "       [0.94846348, 0.05153652],\n",
       "       [0.0424899 , 0.9575101 ],\n",
       "       [0.0691229 , 0.9308771 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        83\n",
      "           1       0.86      0.89      0.87       101\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.86      0.86      0.86       184\n",
      "weighted avg       0.86      0.86      0.86       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our model has an 86% accuracy, which is quite decent. But, it can likely also be improved upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning3",
   "language": "python",
   "name": "deep-learning3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
